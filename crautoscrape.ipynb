{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# crautoscrape\n",
    "\n",
    "A naive and blunt web scraper for http://crautos.com/, along with some trivial graphs courtesy of pandas and matplotlib - in case you ever want to buy or sell a used car in Costa rica!\n",
    "\n",
    "Disclaimer: Whipped together over the weeked mainly by copypasting examples.. whatever. It's incredibly inefficient but solves the task at hand ;)\n",
    "\n",
    "\n",
    "# Installation\n",
    "\n",
    "Set up a python venv and get dependencies - these (shell) instructions work on Fedora 28 - adapt as needed:\n",
    "```\n",
    "python3 -m venv crauto\n",
    "cd crauto\n",
    ". bin/activate\n",
    "pip install jupyter pandas matplotlib beautifulsoup4 dateparser requests\n",
    "jupyter notebook\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - utilities\n",
    "\n",
    "Run this first - after here, run parts selectively depending on what's changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get, post\n",
    "from requests.exceptions import RequestException\n",
    "from contextlib import closing\n",
    "from bs4 import BeautifulSoup\n",
    "import dateparser\n",
    "from IPython.display import display\n",
    "\n",
    "def log_progress(sequence, every=None, size=None, name='Items'):\n",
    "    '''https://github.com/alexanderkuk/log-progress'''\n",
    "\n",
    "    from ipywidgets import IntProgress, HTML, VBox\n",
    "    from IPython.display import display\n",
    "\n",
    "    is_iterator = False\n",
    "    if size is None:\n",
    "        try:\n",
    "            size = len(sequence)\n",
    "        except TypeError:\n",
    "            is_iterator = True\n",
    "    if size is not None:\n",
    "        if every is None:\n",
    "            if size <= 200:\n",
    "                every = 1\n",
    "            else:\n",
    "                every = int(size / 200)     # every 0.5%\n",
    "    else:\n",
    "        assert every is not None, 'sequence is iterator, set every'\n",
    "\n",
    "    if is_iterator:\n",
    "        progress = IntProgress(min=0, max=1, value=1)\n",
    "        progress.bar_style = 'info'\n",
    "    else:\n",
    "        progress = IntProgress(min=0, max=size, value=0)\n",
    "    label = HTML()\n",
    "    box = VBox(children=[label, progress])\n",
    "    display(box)\n",
    "\n",
    "    index = 0\n",
    "    try:\n",
    "        for index, record in enumerate(sequence, 1):\n",
    "            if index == 1 or index % every == 0:\n",
    "                if is_iterator:\n",
    "                    label.value = '{name}: {index} / ?'.format(\n",
    "                        name=name,\n",
    "                        index=index\n",
    "                    )\n",
    "                else:\n",
    "                    progress.value = index\n",
    "                    label.value = u'{name}: {index} / {size}'.format(\n",
    "                        name=name,\n",
    "                        index=index,\n",
    "                        size=size\n",
    "                    )\n",
    "            yield record\n",
    "    except:\n",
    "        progress.bar_style = 'danger'\n",
    "        raise\n",
    "    else:\n",
    "        progress.bar_style = 'success'\n",
    "        progress.value = index\n",
    "        label.value = \"{name}: {index}\".format(\n",
    "            name=name,\n",
    "            index=str(index or '?')\n",
    "        )\n",
    "\n",
    "\n",
    "def simple_get(url):\n",
    "    with closing(get(url, stream=True)) as resp:\n",
    "        if is_good_response(resp):\n",
    "            return resp.content\n",
    "        raise ValueError()\n",
    "def simple_post(url, data):\n",
    "    with closing(post(url, stream=True, data=data)) as resp:\n",
    "        if is_good_response(resp):\n",
    "            return resp.content\n",
    "        raise ValueError()\n",
    "\n",
    "def is_good_response(resp):\n",
    "    content_type = resp.headers['Content-Type'].lower()\n",
    "    return (resp.status_code == 200 \n",
    "            and content_type is not None \n",
    "            and content_type.find('html') > -1)\n",
    "\n",
    "def get_urls(raw_html):\n",
    "    html = BeautifulSoup(raw_html, 'html.parser')\n",
    "    urls = [a['href'] for a in html.select('a') if a['href'].find('cardetail.cfm') > -1]\n",
    "    return [a[16:].split('&')[0] for a in urls]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - download list of ids\n",
    "\n",
    "Each car on crautos has an id - this will download the list and put it in a variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_auto_ids():\n",
    "    # Search pattern - edit it to limit search results from upstream\n",
    "    data = {\n",
    "        \"brand\":\"00\",\n",
    "    \"doors\":\"4\",\n",
    "    \"financed\":\"00\",\n",
    "    \"fuel\":\"0\",\n",
    "    \"modelstr\":\"\",\n",
    "    \"orderby\":\"0\",\n",
    "    \"p\":\"3\",\n",
    "    \"pricefrom\":\"100000\",\n",
    "    \"priceto\":\"200000000\",\n",
    "    \"province\":\"7\",\n",
    "    \"style\":\"00\",\n",
    "    \"trans\":\"0\",\n",
    "    \"yearfrom\":\"1960\",\n",
    "    \"yearto\":\"2018\",\n",
    "    }\n",
    "    \n",
    "    results = set()\n",
    "    \n",
    "    for i in log_progress(range(1, 401), every=1):\n",
    "        data['p']=i\n",
    "        results.update(get_urls(simple_post(\"http://crautos.com/rautosusados/searchresults.cfm\",data)))\n",
    "    return results\n",
    "\n",
    "ids=get_auto_ids()\n",
    "len(ids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 - download car data\n",
    "\n",
    "Each car from the list downloaded in Part2 will be downloaded and cached in a local database.\n",
    "TODO: could prune the database too, of old cards that have already been sold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shelve\n",
    "\n",
    "def get_car(id):\n",
    "    return simple_get(\"http://crautos.com/rautosusados/cardetail.cfm?c=\" + str(id))\n",
    "\n",
    "with shelve.open('crautos') as d:\n",
    "    for id in ids:\n",
    "        if id in d:\n",
    "            continue\n",
    "        display(\"Getting \" + str(id))\n",
    "        d[id]=get_car(id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4 - load and convert to HTML objects\n",
    "\n",
    "Load the database from Part 3 and parse into BeautifulSoup html objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import shelve\n",
    "\n",
    "parsed = {}\n",
    "with shelve.open('crautos') as d:\n",
    "    for k,v in d.items():\n",
    "        try:\n",
    "            parsed[k]=BeautifulSoup(v)\n",
    "        except AttributeError:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5 - parse into pandas DataFrame\n",
    "\n",
    "Pick out interesting parts of HTML and build a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_car(html):\n",
    "    results={}\n",
    "    \n",
    "    makes = html.find('div', class_='col-lg-8 col-md-8 col-sm-8 col-xs-12').find('h2')\n",
    "    name, *_, year = makes\n",
    "    results['name']=str(name)\n",
    "    results['year']=int(year)\n",
    "    \n",
    "    price = html.find('div', class_='col-lg-4 col-md-4 col-sm-4 text-right').find('h2')\n",
    "    results['price']=int(price.text[1:].replace(',',''))/567\n",
    "    \n",
    "    tbl = html.find('table', attrs={'class':'technical'})\n",
    "\n",
    "    for d in tbl.find_all('tr'):\n",
    "        tds = d.find_all('td')\n",
    "        if len(tds) != 2: \n",
    "            continue\n",
    "        results[tds[0].text.strip()]=tds[1].text.strip()\n",
    "\n",
    "    if 'Kilometraje' in results:\n",
    "        results['Kilometraje'] =int( results['Kilometraje'].replace(' km', '').replace(',', ''))\n",
    "    if 'Fecha de ingreso' in results:\n",
    "        results['Fecha de ingreso'] = dateparser.parse(results['Fecha de ingreso'], locales=['es-CR'])\n",
    "        \n",
    "    return results\n",
    "\n",
    "\n",
    "df_raw = pd.DataFrame()\n",
    "\n",
    "for k,v in parsed.items():\n",
    "    try:\n",
    "        v = parse_car(v)\n",
    "        df_raw = df_raw.append(pd.DataFrame(v, index=[k]))\n",
    "    except (ValueError,AttributeError):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 6 - look at data\n",
    "\n",
    "This is where the fun starts :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "with pd.option_context('display.max_rows', None):\n",
    "    df = df_raw.copy().query('price>0 & Kilometraje>0')\n",
    "    df.groupby(['year','name']).mean().sort_values('price')\n",
    "    rav=df[df['name'].str.contains('BMW X3')].query('price>0 & Kilometraje>0')\n",
    "    rav.plot.scatter(x='Kilometraje', y='year')\n",
    "    rav.plot.scatter(x='price', y='year')\n",
    "    rav.plot.scatter(x='price', y='Kilometraje')\n",
    "\n",
    "    display(rav.sort_values(['Fecha de ingreso', 'year','price']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', 4):\n",
    "    display(df[df['Estilo'].str.contains('no 4x4')].groupby(['name']).count() .reset_index() .sort_values('year', ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_raw.copy().query('price>0 & Kilometraje>0 & year >= 2000')\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', 3):\n",
    "    display(df.groupby(['year','name','Estilo']).mean().sort_values(['year', 'Estilo','price']))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
